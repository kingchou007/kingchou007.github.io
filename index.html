<!DOCTYPE HTML>
<html>
  <head>
    <!-- Google analytics tag (gtag.js) -->
    <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-STGLQW4BJX"></script> -->
     <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
      new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
      j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
      })(window,document,'script','dataLayer','GTM-MWZCW9SM');</script>
      <!-- End Google Tag Manager -->

    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-STGLQW4BJX');
    </script>

    <!-- Title -->
    <title>Jinzhou Li</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=1000">
    
    <!-- SEO Meta Tags -->
    <meta name="description" content="Jinzhou Li - PhD student in Robotics at Duke University. Research interests include dexterous manipulation, multimodal learning, and reinforcement learning.">
    <meta name="author" content="Jinzhou Li">
    
    <!-- Open Graph Meta Tags -->
    <meta property="og:title" content="Jinzhou Li">
    <meta property="og:description" content="PhD student in Robotics at Duke University, advised by Prof. Xianyi Cheng. Research interests include dexterous manipulation, multimodal learning, and reinforcement learning.">
    <meta property="og:image" content="https://kingchou007.github.io/images/ljz2025head.jpg">
    <meta property="og:url" content="https://kingchou007.github.io/">
    <meta property="og:type" content="website">
    

    <!-- Isotope JS -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.13.2/jquery-ui.min.js"></script>
    <script src="https://unpkg.com/isotope-layout@3/dist/isotope.pkgd.min.js"></script>
    <script src="https://unpkg.com/imagesloaded@5/imagesloaded.pkgd.min.js"></script>

    <!-- Custom Style -->
    <link rel="stylesheet" href="style.css">

    <!-- Google Font -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Asap:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap" rel="stylesheet">
    <style>
      @import url('https://fonts.googleapis.com/css2?family=Asap:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap');
    </style>
  </head>

  <body id="body">

    <div id="main">
      <div id="intro">
        <div id="intro-text">
          <h1>Jinzhou Li</h1>
          <div id="more-bio" style="display: block">
            <!-- <p>Jinzhou is a PhD student in Robotics at Duke University, advised by <a href="https://xianyicheng.github.io/">Prof. Xianyi Cheng</a>. Before that, he worked with <a href="https://zsdonghao.github.io">Prof. Hao Dong</a> at Peking University. Jinzhou also had the opportunity to work with <a href="https://www.linkedin.com/in/mhaji/">Prof. Maha Haji</a> at Cornell and <a href="https://aeroastro.mit.edu/people/daniel-e-hastings">Prof. Daniel Hastings</a> at MIT. 
              He received his master’s degree from Cornell University and his undergraduate degree from the University of Vermont. His research interests focus on Manipulation, multimodal learning, and robot learning to enable robots to act and think like humans. If you want to chat, feel free to drop me an email!
            </p> -->
            <p>
              I am a first-year PhD student in Robotics at Duke University, advised by 
              <a href="https://xianyicheng.github.io/">Prof. Xianyi Cheng</a>. 
              Before Duke, I worked with <a href="https://zsdonghao.github.io">Prof. Hao Dong</a> at Peking University.
                            
                I did my master's at Cornell University, where I was advised by 
                <a href="https://sea.mae.cornell.edu/team/">Prof. Maha Haji</a>, and completed my bachelor's degree at the University of Vermont.
                            
              I also had the chance to work with 
              <a href="https://aeroastro.mit.edu/people/daniel-e-hastings">Prof. Daniel Hastings</a> at MIT.
    
              My research interests focus on manipulation, multimodal learning, and robot learning, with the goal of enabling robots to act and think more like humans.
              I'm always happy to chat — feel free to reach out!
              </p>
          </div>
          <br>
          <p>
            <a href="mailto:jinzhou.li@duke.edu">Email</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://twitter.com/Kingchou007Li">X</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://scholar.google.com/citations?hl=en&user=s93qhQ8AAAAJ&view_op=list_works">Google Scholar</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://www.linkedin.com/in/jinzhou-l-78001212a/">LinkedIn</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://github.com/kingchou007">Github</a>
          </p>
          <br>
        </div>
        <div id="intro-image">
          <img src="images/Ghibli-JZ.png" class="profile-img active" alt="jinzhou">
          <img src="images/ljz2025head.jpg" class="profile-img" alt="jinzhou">
          <img src="images/travel.jpg" class="profile-img" alt="jinzhou">
           <img src="images/hiking.png" class="profile-img" alt="jinzhou">
           <div class="image-hint">Click to switch image~</div>
        </div>
      </div>

      <div id="filters" class="button-group">
        <!-- <button class="button" data-filter=".highlight">Highlight</button> -->
        <button class="button is-checked" data-filter=".publication">Research</button>
        <button class="button" data-filter=".misc">Misc</button>
        <!-- <button class="button" data-filter=".blog">Blog</button> -->
        <!-- Services [in the future] -->
      </div>

      <div class="grid">

        

        <!-- <div class="list-item highlight" data-category="highlight">
          <section id="research-highlights">
            <p class="rh-lead">
              Building dexterous robots with multimodal sensing.
            </p>

            <div class="rh-card primary">
              <h3>Dexterous Multimodal Manipulation</h3>
              <p>Unified visuo-tactile representations for contact-rich manipulation.</p>
              <span class="rh-toggle" style="cursor: pointer; color: #146ebe; text-decoration: underline; user-select: none;">Show/Hide Work</span>
            </div>

            <div class="rh-row">
              <div class="rh-card pill">
                <strong>Unified Multimodal Representation</strong>
                <p></p>
              </div>
              <div class="rh-card pill">
                <strong>Contact-Rich Manipulation</strong>
                <p>Manipulation with multiple contacts.</p>
              </div>
              <div class="rh-card pill">
                <strong>Inference Time Scaling</strong>
                <p>Scale from seconds to milliseconds.</p>
              </div>
              <div class="rh-card pill">
                <strong>Robust Manipulation</strong>
                <p>Robust control under uncertainty.</p>
              </div>
            </div>
          </section>
        </div> -->

        <!-- Preview Videos -->
        <!-- <div class="list-item highlight previews" data-category="highlight">

          <a href="https://palm-e.github.io/"><video class="preview1" playsinline="" muted="" autoplay="" loop=""><source src="images/video-palm-e.mp4" type="video/mp4"></video></a>

          <a href="https://say-can.github.io/"><video class="preview2" playsinline="" muted="" autoplay="" loop=""><source src="images/video-saycan.mp4" type="video/mp4"></video></a>

          <a href="https://tossingbot.cs.princeton.edu/"><video class="preview3" playsinline="" muted="" autoplay="" loop=""><source src="images/video-tossingbot-crop.mp4" type="video/mp4"></video></a>
        </div>  -->

        <!-- Truncated Set of Highlights (Shown by Default) -->
        <!-- <div id="main-highlights">

          <div class="list-item highlight" data-category="highlight">
            <b>CoRL</b> <a href="https://robot-help.github.io/">Best Student Paper Award</a>
          </div>

          <div class="list-item highlight" data-category="highlight">
            <b>ICRA</b> <a href="https://code-as-policies.github.io/">Outstanding Learning Paper Award</a>
          </div>

          <div class="list-item highlight" data-category="highlight">
            <b>Google AI</b> blog post <a href="https://ai.googleblog.com/2022/11/robots-that-write-their-own-code.html">"Robots That Write Their Own Code"</a>
          </div> -->


        <!-- </div> -->

        <div class="list-item publication toggle-button" data-category="publication">
          <p>
            <!-- Show by date order (most recent first) <br> -->
            Note: * means equal contribution
          </p>
        </div> 


        <!-- Publications -->
        <!-- <div class="list-item publication description" data-category="publication">
          Selected publications:
        </div>  -->

        <div id="main-highlights">
          <!-- <br> -->
          <div class="list-item publication" data-category="publication">
            <a href="" class="thumbnail">
              <img src="images/project_opentouch.gif" alt="opentouch" />
            </a>
            <div class="project-description">
              <h3><a href="">OpenTouch: Bringing Full-Hand Touch to Real-World Interaction</a></h3>
              <p>
                Yuxin Ray Song*, 
                <b><u>Jinzhou Li</u></b>*, 
                Rao Fu*, 
                Devin Murphy, 
                Kaichen Zhou, 
                Rishi Shiv, 
                Yaqi Li, 
                Haoyu Xiong, 
                Crystal Elaine Owens, 
                Yilun Du, 
                Yiyue Luo, 
                Xianyi Cheng, 
                Antonio Torralba, 
                Wojciech Matusik, 
                Paul Pu Liang
                <br>
                <i>Technical Report</i><br>
                  <a href="https://opentouch-tactile.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/2512.16842">Paper</a>
              </p>
            </div>
          </div>

          <div class="list-item publication" data-category="publication">
            <a href="" class="thumbnail">
              <img src="images/hierarchical-multi-frequency.webp" alt="Hierarchical-Multi-Frequency" />
            </a>
            <div class="project-description">
              <h3><a href="">Hierarchical Policy: Multi-Frequency Action Chunking across Hierarchical Temporal Resolutions for Robotic Imitation Learning</a></h3>
              <p>
                Jiyao Zhang, 
                Zimu Han, 
                Junhan Wang, 
                Xionghao Wu, 
                Shihong Lin, 
                <b><u>Jinzhou Li</u></b>, 
                Hongwei Fan, 
                Ruihai Wu, 
                Dongjiang Li, 
                Hao Dong
                <br><i>Under Review</i><br>
                  <!-- <a href="">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="">Paper</a> -->
              </p>
            </div>
          </div>

          <div class="list-item publication" data-category="publication">
            <a href="" class="thumbnail">
              <img src="images/twin-align.webp" alt="twinaligner" />
            </a>
            <div class="project-description">
              <h3><a href="">TwinAligner: Visual-Dynamic Alignment Empowers Physics-aware Real2Sim2Real for Robotic Manipulation</a></h3>
              <p>
                Hongwei Fan*,
                Hang Dai*,  
                Jiyao Zhang*,  
                <b><u>Jinzhou Li</u></b>,
                Qiyang Yan,
                Yujie Zhao,
                Mingju Gao,
                Jinghang Wu,
                Hao Tang,
                Hao Dong<br>
                  <i>Under Review</i> <br>
                  <!-- <a href="">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="">Paper</a> -->
                  <!-- &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="">Code</a>
                  &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="">Real2Sim2Real</a>
                  &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="">Video</a> -->
              </p>
            </div>
          </div>

          <div class="list-item publication" data-category="publication">
            <a href="https://clutterdexgrasp.github.io/" class="thumbnail">
              <video class="preview" src="images/clutterdexgrasping_480p.mp4" alt="clutterdexgrasping" autoplay muted loop playsinline style="max-width:100%;height:auto;"></video>
            </a>
            <div class="project-description">
              <h3><a href="https://clutterdexgrasp.github.io/">ClutterDexGrasp: A Sim-to-Real System for General Dexterous Target Grasping in
                Cluttered Scenes</a></h3>
              <p>
                Zeyuan Chen*, Qiyang Yan*, Yuanpei Chen*, Tianhao Wu, Jiyao Zhang, Zihan Ding, <b><u>Jinzhou Li</u></b>, Yaodong Yang, Hao Dong<br>
                  <i>Conference on Robot Learning (CoRL) 2025</i> <br>
                  <span><b><i>Oral Presentation (~5% of total accepted papers)</i></b></span><br>
                  <a href="https://clutterdexgrasp.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://arxiv.org/html/2506.14317v2">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://github.com/QiyangYan/ClutterDexGrasp">Code</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://www.youtube.com/watch?v=RuSxGEG-nlc">Video</a>
              </p>
            </div>
          </div>

          <div class="list-item publication" data-category="publication">
            <a href="https://adaptac-dex.github.io/" class="thumbnail">
              <img src="images/adaptac.png" alt="adaptac-dex" /></a>
            <div class="project-description">
              <h3><a href="https://adaptac-dex.github.io/">AdapTac-Dex: Adaptive Visuo-Tactile Fusion with Predictive Force Attention for Dexterous Manipulation</a></h3>
              <p>
                <b><u>Jinzhou Li</u></b>*,
                Tianhao Wu*,
                Jiyao Zhang**, 
                Zeyuan Chen**, 
                Haotian Jin, 
                Mingdong Wu,
                Yujun Shen,
                Yaodong Yang,
                Hao Dong<br>
                  <i>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2025</i><br>
                  <a href="https://adaptac-dex.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/2505.13982">Paper</a>
                  &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://github.com/kingchou007/adaptac-dex">Code</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://drive.google.com/drive/folders/1dJnF192aBb8VxeNBQRBstrCrC3GcPKho">Hardware</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://youtu.be/Aq34cDWNBE8?si=NWS9lV_0zPq7um7w">Video</a>
              </p>
            </div>
          </div>

          <div class="list-item publication" data-category="publication">
            <a href="https://arxiv.org/abs/2507.04452" class="thumbnail"><img src="images/simlauncher.png" alt="" /></a>
            <div class="project-description">
              <h3><a href="https://arxiv.org/abs/2507.04452">SimLauncher: Launching Sample-Efficient Real-world Robotic Reinforcement Learning via Simulation Pre-training</a></h3>
              <p>
                Mingdong Wu*,
                Lehong Wu*,  
                Yizhuo Wu*,  
                Weiyao Huang,
                Hongwei Fan,
                Zheyuan Hu,
                Haoran Geng,
                <b><u>Jinzhou Li</u></b>,
                Jiahe Ying,
                Long Yang,
                Yuanpei Chen,
                Hao Dong
                <br>
                  <i>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2025</i><br>
                  <a href="https://simlauncher.github.io/#">Webpage</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/2507.04452">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://kingchou007.github.io/images/Training%20Timelapse.mp4">Video</a>
              </p>
            </div>
          </div>

          <div class="list-item publication" data-category="publication">
            <a href="https://3dtacdex.github.io/" class="thumbnail"><img src="images/pretrain-3dtac-dex.png" alt="" /></a>
            <div class="project-description">
              <h3><a href="https://3dtacdex.github.io/">Canonical Representation and Force-Based Pretraining of 3D Tactile for Dexterous Visuo-Tactile Policy Learning</a></h3>
              <p>
                Tianhao Wu,
                <b><u>Jinzhou Li</u></b>*,
                Jiyao Zhang*, 
                Mingdong Wu,
                Hao Dong<br>
                  <i>IEEE International Conference on Robotics and Automation (ICRA) 2025 </i><br>
                 
                  <a href="https://3dtacdex.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://arxiv.org/pdf/2409.17549">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://github.com/tianhaowuhz/3dtacdex">Code</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://youtu.be/j8Vtia1AWZk?si=raCvWzEz-edATnQ9">Video</a>
              </p>
            </div>
          </div>

  

        </div>

        <!-- INSERT_YOUR_CODE -->
        <!-- All Publications (Click to Show) -->
        <!-- <div id="more-highlights" style="display: None">

          <div class="list-item publication" data-category="publication">
            <a href="https://robot-teaching.github.io/" class="thumbnail">
              <video playsinline="" muted="" autoplay="" loop="" width="180px">
                <source src="images/daynight.mp4" type="video/mp4">
              </video>
            </a>
            <div class="project-description">
              <h3><a href="https://robot-teaching.github.io/">Learning to Learn Faster from Human Feedback with Language Model Predictive Control</a></h3>
              <p>
                Jacky Liang, Fei Xia, Wenhao Yu, Andy Zeng, Montserrat Gonzalez Arenas, Maria Attarian, Maria Bauza, Matthew Bennice, Alex Bewley, Adil Dostmohamed, Chuyuan Kelly Fu, Nimrod Gileadi, Marissa Giustina, Keerthana Gopalakrishnan, Leonard Hasenclever, Jan Humplik, Jasmine Hsu, Nikhil Joshi, Ben Jyenis, Chase Kew, Sean Kirmani, Tsang-Wei Edward Lee, Kuang-Huei Lee, Assaf Hurwitz Michaely, Joss Moore, Ken Oslund, Dushyant Rao, Allen Ren, Baruch Tabanpour, Quan Vuong, Ayzaan Wahid, Ted Xiao, Ying Xu, Vincent Zhuang, Peng Xu, Erik Frey, Ken Caluwaerts, Tingnan Zhang, Brian Ichter, Jonathan Tompson, Leila Takayama, Vincent Vanhoucke, Izhak Shafran, Maja Mataric, Dorsa Sadigh, Nicolas Heess, Kanishka Rao, Nik Stewart, Jie Tan, Carolina Parada<br>
                  <i>Robotics: Science and Systems (RSS) 2024</i><br>
                  <a href="https://robot-teaching.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/2402.11450">PDF</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://colab.research.google.com/drive/1YcRN_kklw3cVVJNvgK_IEV6nDce9EJWK?usp=sharing">Code</a>
                  <br> <!-- TODO: extra spaces until I figure out the margin bug. -->
              <!-- </p>
            </div>
          </div> -->

        <!-- </div> --> 
        

        <!-- Toggle highlights button. -->
        <!-- <div class="list-item publication toggle-button" data-category="publication">
          <p>
            For a complete and up-to-date list of my publications, please visit my 
            <a id="toggle_highlights_button" href="https://scholar.google.com/citations?hl=en&user=s93qhQ8AAAAJ&view_op=list_works" target="_blank"><b>Google Scholar</b></a>.
          </p>
        </div>  -->




        <!-- Talks -->
        <div class="list-item blog description" data-category="blog">
        </div> 
        <!-- <div class="list-item blog" data-category="blog">
          <p class="date">2025</p>
            <span><a href="">Learning from Human Data</a></span>
        </div>

         <div class="list-item blog" data-category="blog">
          <p class="date"></p>
            <span><a href="https://kane007.notion.site/Why-Phd-2cd8313477a38026b7b6ecf1aa71a06c?source=copy_link">Why PhD? Reflections on My Research Journey</a></span>
        </div> -->





        <!-- Misc (News) -->
        <div class="list-item misc" data-category="misc">
          <!-- <p class="date">2026</p>
          <span>One paper accepted to ICRA 2026.</span>
        </div>  -->

        <div class="list-item misc" data-category="misc">
          <p class="date">2025</p>
          <span>Joined Duke University as a PhD student, advised by <a href="https://xianyicheng.github.io/">Prof. Xianyi Cheng</a></span>
        </div>

        <div class="list-item misc" data-category="misc">
          <p class="date"></p>
            One paper accepted to CoRL 2025, selected for <span style="color: red;"><b>Oral Presentation</b></span>
        </div>

        <div class="list-item misc" data-category="misc">
          <p class="date"></p>
          <span>Invited talk at 3D Vision Workshop</a></span>
        </div>

        <div class="list-item misc" data-category="misc">
          <p class="date"></p>
          <span>Two papers accepted to IROS 2025 as oral presentations</span>
        </div>

        <div class="list-item misc" data-category="misc">
          <p class="date"></p>
          <span> Invited talk at Peking University about "AdapTac-Dex"</span>
        </div>

        <div class="list-item misc" data-category="misc">
          <p class="date"></p>
          <span>One paper accepted to ICRA 2025</span>
        </div>

        <div class="list-item misc" data-category="misc">
          <p class="date">2024</p>
          <span>Joined <strong>Peking University</strong> as a visiting student, advised by <a href="https://zsdonghao.github.io">Prof. Hao Dong</a></span>
        </div>

        <div class="list-item misc" data-category="misc">
          <div class="separator"></div>
        </div>

        <div class="list-item misc" data-category="misc">
          <div class="reviewer-info">
            <h4>Reviewer: ICRA 2024, 2025, 2026</h4>
          </div>
        </div>


  

      </div>

      <div id="footer">Inspired by <a href="https://github.com/andyzeng/andyzeng.github.io">Andy Zeng's website</a>.</div>

    </div>

    <!-- <div id="footer"></div><script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=YJ5tJC9Cdj8baVhSikHNQIW1U0rlJuKC09z8yCFRKEI'></script></div> -->

    <script>

      // Isotope grid.
      var $grid = $('.grid').isotope({
        itemSelector: '.list-item',
        layoutMode: 'fitRows',
        transitionDuration: 0,
        stagger: 10,
        initLayout: true,
        getSortData: {
          name: '.name',
          symbol: '.symbol',
          number: '.number parseInt',
          category: '[data-category]',
          weight: function( itemElem ) {
            var weight = $( itemElem ).find('.weight').text();
            return parseFloat( weight.replace( /[\(\)]/g, '') );
          }
        }
      });

      // Bind filter button click.
      $('#filters').on( 'click', 'button', function() {
        var filterValue = $( this ).attr('data-filter');
        localStorage.setItem('filterValue', filterValue);
        $grid.isotope({ filter: filterValue });
      });

      // Change is-checked class on buttons.
      $('.button-group').each( function( i, buttonGroup ) {
        var $buttonGroup = $( buttonGroup );
        $buttonGroup.on( 'click', 'button', function() {
          $buttonGroup.find('.is-checked').removeClass('is-checked');
          $( this ).addClass('is-checked');
        });
      });

      function update_isotope() {
        // Retrieve cached button click.
        var defaultFilterValue = localStorage.getItem('filterValue');
        if (defaultFilterValue == null || defaultFilterValue === ".highlight") {
          defaultFilterValue = ".publication"
        }
        $grid.isotope({ filter: defaultFilterValue });
        var buttons = document.getElementsByClassName("button");
        for (var currButton of buttons) {
          if (currButton.getAttribute('data-filter') == defaultFilterValue) {
            currButton.classList.add('is-checked');
          } else {
            currButton.classList.remove('is-checked');
          }
        }
      }

      function toggle_bio() {
        var x = document.getElementById("more-bio");
        if (x.style.display === "none") {
          x.style.display = "block";
        } else {
          x.style.display = "none";
        }
      }

      function toggle_highlights() {
        var x = document.getElementById("main-highlights");
        var y = document.getElementById("more-highlights");
        var b = document.getElementById("toggle_highlights_button")
        if (y.style.display === "none") {
          x.style.display = "none";
          y.style.display = "block";
          b.innerHTML = "Show less publications"
          update_isotope();
        } else {
          x.style.display = "block";
          y.style.display = "none";
          b.innerHTML = "Show more publications"
          update_isotope();
        }
      }

      // Profile image switching
      function switchProfileImage() {
        var images = $('.profile-img');
        var activeIndex = images.filter('.active').index();
        var nextIndex = (activeIndex + 1) % images.length;
        
        images.eq(activeIndex).removeClass('active');
        images.eq(nextIndex).addClass('active');
      }

      // Click to manually switch
      $('#intro-image').on('click', function() {
        switchProfileImage();
      });

      // Initialize on DOM ready, then update as images load
      $(function() {
        // Apply filter immediately on load
        update_isotope();
        
        // Update layout as images load to prevent jumping
        $grid.imagesLoaded().progress(function() {
          $grid.isotope('layout');
        });
      });

    </script>
  </body>
</html>
